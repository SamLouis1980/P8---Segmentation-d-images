from fastapi import FastAPI, File, UploadFile, Response, Query
import numpy as np
import cv2
from tensorflow.keras.models import load_model
from model_loader import load_model, MODEL_PATHS
from io import BytesIO
from PIL import Image
import uvicorn
import os
import logging

# Configuration du logging pour afficher les logs DEBUG
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler()  # Affichage dans la console
    ]
)

logging.debug("üöÄ Logging DEBUG activ√© !")

os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

app = FastAPI()

# Liste des mod√®les disponibles
AVAILABLE_MODELS = list(MODEL_PATHS.keys())

# Palette officielle Cityscapes
CLASS_COLORS = {
    0: (0, 0, 0),        # Void
    1: (128, 64, 128),   # Flat
    2: (70, 70, 70),     # Construction
    3: (153, 153, 153),  # Object
    4: (107, 142, 35),   # Nature
    5: (70, 130, 180),   # Sky
    6: (220, 20, 60),    # Human
    7: (0, 0, 142)       # Vehicle
}

def colorize(mask):
    """Applique des couleurs aux classes segment√©es selon la palette Cityscapes."""
    color_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)
    for class_id, color in CLASS_COLORS.items():
        color_mask[mask == class_id] = color
    return color_mask

@app.post("/predict/")
def predict(file: UploadFile = File(...), model_name: str = Query("unet_mini", enum=AVAILABLE_MODELS)):
    """Endpoint qui prend une image en entr√©e, applique la segmentation et retourne le masque coloris√©."""

    # V√©rification du format et de la taille
    if file.content_type not in ["image/jpeg", "image/png"]:
        return {"error": "Format non support√©. Utilisez JPEG ou PNG."}
    if file.size > 10 * 1024 * 1024:
        return {"error": "Image trop grande. Taille max: 10MB."}

    # Charger l'image
    image = Image.open(BytesIO(file.file.read())).convert("RGB")

    # Obtenir la taille d'entr√©e du mod√®le s√©lectionn√©
    if model_name not in MODEL_INPUT_SIZES:
        return {"error": f"Mod√®le inconnu {model_name}. Mod√®les disponibles : {AVAILABLE_MODELS}"}

    input_size = MODEL_INPUT_SIZES[model_name]  # Taille correcte du mod√®le

    logging.debug(f"[DEBUG] Mod√®le s√©lectionn√© : {model_name}")
    logging.debug(f"[DEBUG] Taille d'entr√©e attendue : {input_size}")
    logging.debug(f"[DEBUG] Taille originale de l'image : {image.size}")

    # Redimensionner l'image √† la taille d'entr√©e du mod√®le
    image = image.resize(input_size, Image.BILINEAR)
    logging.debug(f"[DEBUG] Taille apr√®s redimensionnement : {image.size}")

    # Pr√©parer l'image pour le mod√®le
    image_array = np.array(image) / 255.0  # Normalisation
    image_array = np.expand_dims(image_array, axis=0)  # Ajouter une dimension batch
    logging.debug(f"[DEBUG] Shape du tenseur avant pr√©diction : {image_array.shape}")

    # Charger le mod√®le
    model = load_model(model_name)
    
    # V√©rification de la taille d'entr√©e du mod√®le
    if image_array.shape[1:3] != input_size:
        logging.error(f"[ERREUR] Taille de l'image incorrecte : {image_array.shape[1:3]}, attendu : {input_size}")
        return {"error": f"Taille incorrecte : {image_array.shape[1:3]} au lieu de {input_size}"}

    # Pr√©diction
    prediction = model.predict(image_array)
    logging.debug(f"[DEBUG] Pr√©diction termin√©e. Shape sortie : {prediction.shape}")

    # Extraction du masque et application de la palette
    mask = np.argmax(prediction[0], axis=-1)
    color_mask = colorize(mask)

    # Convertir en image PNG
    _, buffer = cv2.imencode(".png", color_mask)

    logging.info(f"[INFO] Pr√©diction r√©ussie, image renvoy√©e au client.")

    return Response(buffer.tobytes(), media_type="image/png")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
